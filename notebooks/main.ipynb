{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.utils as utils\n",
    "import app\n",
    "from utils.ipynb_pipeline import create_file_selector, get_selected_file_paths\n",
    "\n",
    "source_language = \"it\"\n",
    "target_language = \"en\"\n",
    "input_path = \"/Users/ramiibrahimi/Documents/test.nosync/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions = [\".mp4\", \".wmv\", \".mpg\", \".srt\", \".mov\"]\n",
    "# extensions = [\".wmv\"]\n",
    "\n",
    "dropdown, file_map = create_file_selector(input_path, extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = get_selected_file_paths(dropdown, file_map)\n",
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# multiple concurrent transcriptions\n",
    "server_region = \"us-central1\"  # for google chirp europe-west4 or us-central1. global for google long\n",
    "services = [\"openai\", \"google\"]\n",
    "file_lock = threading.Lock()\n",
    "\n",
    "\n",
    "def process_single_file(\n",
    "    service_name, file_path, source_language, target_language, server_region\n",
    "):\n",
    "    \"\"\"Process a single file with a single service\"\"\"\n",
    "    try:\n",
    "        # Add a small delay to prevent race conditions\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        response = app.multi_transcribe(\n",
    "            file_path=file_path,\n",
    "            service_names=[service_name],\n",
    "            source_language=source_language,\n",
    "            target_language=target_language,\n",
    "            audio_output_extension=\".flac\",\n",
    "            server_region=server_region,\n",
    "        )\n",
    "\n",
    "        srt_response = response[service_name]\n",
    "        print(f\"{service_name} completed: {file_path}\")\n",
    "        # Use thread lock for file operations if needed\n",
    "\n",
    "        with file_lock:\n",
    "            download_path = utils.replace_extension(\n",
    "                file_path=file_path,\n",
    "                end_modifiers=f\"_{service_name}\",\n",
    "                new_extension=\".srt\",\n",
    "            )\n",
    "            utils.save_srt_data(srt_data=srt_response, file_path=download_path)\n",
    "\n",
    "        return f\"{service_name}: {file_path} - Success\"\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "\n",
    "        error_msg = f\"Error processing {file_path} with {service_name}: {e}\\nTraceback: {traceback.format_exc()}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "\n",
    "def process_service_files(\n",
    "    service_name,\n",
    "    file_paths,\n",
    "    source_language,\n",
    "    target_language,\n",
    "    server_region,\n",
    "    max_workers=1,\n",
    "):\n",
    "    \"\"\"Process all files for a single service using ThreadPoolExecutor\"\"\"\n",
    "    print(f\"Starting {service_name} processing with {max_workers} workers...\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all file processing tasks for this service\n",
    "        future_to_file = {\n",
    "            executor.submit(\n",
    "                process_single_file,\n",
    "                service_name,\n",
    "                file_path,\n",
    "                source_language,\n",
    "                target_language,\n",
    "                server_region,\n",
    "            ): file_path\n",
    "            for file_path in file_paths\n",
    "        }\n",
    "\n",
    "        # Process completed tasks\n",
    "        for future in as_completed(future_to_file):\n",
    "            result = future.result()\n",
    "            # Result is already printed in process_single_file\n",
    "\n",
    "    print(f\"Finished {service_name} processing\")\n",
    "\n",
    "\n",
    "# Create and start threads - one per service\n",
    "threads = []\n",
    "for service in services:\n",
    "    thread = threading.Thread(\n",
    "        target=process_service_files,\n",
    "        args=(\n",
    "            service,\n",
    "            file_paths,\n",
    "            source_language,\n",
    "            target_language,\n",
    "            server_region,\n",
    "            1,\n",
    "        ),  # 3 workers per service\n",
    "    )\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(\"All transcription services completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
